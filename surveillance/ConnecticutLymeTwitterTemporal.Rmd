---
title: "ConnecticutLymeTwitterTemportal"
output:
  pdf_document: default
  html_document: default
date: '2022-05-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r packages}
# https://cran.r-project.org/web/packages/surveillance/vignettes/hhh4_spacetime.pdf

# install.packages("surveillance")
# install.packages("spdep")
# install.packages("maps")
# install.packages("maptools")
# install.packages("classInt")
# install.packages("RColorBrewer")
# install.packages("fanplot")
# 
# install.packages("rgdal")
# 
# install.packages("dplyr")
# install.packages("UScensus2000tract")
# install.packages("spatialreg")
# install.packages("Matrix")
# install.packages("caret")

library(surveillance)
library(spdep)
library(maps)
library(maptools)
library(classInt)
library(RColorBrewer)
library(rgdal)
library(fanplot)
library(spatialreg)
library(Matrix)
library(dplyr)
library(ggplot2)
library(sf)
library(stringr)
library(UScensus2000tract)
# library(caret)

```

```{r data}

observed = read.csv("connecticut.csv", header=FALSE)

observed[is.na(observed)] = 0

# Delete first 12 rows for 2009 year as we have only census data from 2010 till 2018.
observed = observed[13:120,]
head(observed)

mycounty = map("county","connecticut", fill=TRUE, plot=FALSE)
county.ID <- sapply(strsplit(mycounty$names, ","), function(x) x[2])
mypoly = map2SpatialPolygons(mycounty, IDs=county.ID)
county_adjmat <- poly2adjmat(mypoly)
county_nbOrder <- nbOrder(county_adjmat, maxlag = 1)
colnames = colnames(county_nbOrder)
colnames(observed) = colnames

cdcCon = sts(observed, start=c(2010,1), freq=12)
cdcCon



```

## Including Plots

You can also embed plots, for example:

```{r temporal model}

plot(cdcCon, type = observed ~ time | unit, same.scale = FALSE, col = "grey")
f_S1 <- addSeason2formula(f = ~ 1, S = 1, period = 10)
negBinModel <- hhh4(cdcCon, control = list(end = list(f = f_S1),
                                     family = "NegBin1"))
summary(poiModel)

possnModel <- update(negBinModel, family = "Poisson")
summary(possnModel)

ar1Model <- update(negBinModel, ar = list(f = ~ 1))

summary(ar1Model)

AIC(possnModel, negBinModel, ar1Model)


coef(ar1Model, se = TRUE,    # also return standard errors
     amplitudeShift = TRUE, # transform sine/cosine coefficients
     # to amplitude/shift parameters
     idx2Exp = TRUE)


```

```{r population for spatial analysis}

popConn = read.csv("census_connecticut_county_2010_2018.csv")

popConn = popConn[ -c(1) ]

popFrac = popConn/100000

colnames(popFrac) = colnames

dfDisprogNb <- sts(observed, start = c(2010, 1), frequency = 12, population = data.matrix(popFrac),
                   neighbourhood = county_state_nbOrder, map = mn.poly)

```


```{r spatial-temporal-lyme-tweet}

observedTwt = read.csv("connecticutTwts.csv")
observedTwt[is.na(observedTwt)] = 0

observedTwt = observedTwt[-c(1)]
colnames(observedTwt) = colnames

observedTwt = sapply(observedTwt, as.numeric)

t = 12
f.end <- addSeason2formula(f = ~ 1, S = 1, period = t)
lymeTwtModel_basic <- list(ar = list(f = ~1 + observedTwt), ne = list(f = ~1, weights = county_state_nbOrder == 1), end = list(f = f.end),
 data = list(t = epoch(dfDisprogNb), observedTwt = observedTwt))

lymeTwtFit_basic <- hhh4(stsObj = dfDisprogNb, control = lymeTwtModel_basic)
summary(lymeTwtModel_basic, idx2Exp = TRUE, amplitudeShift = TRUE, maxEV = TRUE)
plot(lymeTwtFit_basic, type = "season", components = "end", main = "")


districts2plot <- which(colSums(observed) > 50)

par(mfrow = c(2,4), mar = c(3, 1, 2, 1), las = 1)

plot(lymeTwtFit_basic, type = "fitted", units = districts2plot, hide0s = TRUE, par.settings = NULL, legend = 1) -> all_counties

plot(lymeTwtFit_basic, type = "fitted", total = TRUE, hide0s = TRUE, par.settings = NULL, legend = FALSE) -> fitted_components




```


```{r Statistical Tests}

pred <- oneStepAhead(lymeTwtFit_basic, nrow(observed)-5, type="rolling", which.start="final", verbose=FALSE)
pred
quantile(pred)
confint(pred)

## simple plot of the 80% one-week-ahead prediction interval
## and point forecasts
if (requireNamespace("fanplot"))
    plot(pred, probs = c(.1,.9), means.args = list())


## note: oneStepAhead(..., type="final") just means fitted values
stopifnot(identical(
    unname(oneStepAhead(result2, nrow(observed)-5, type="final")$pred),
    unname(tail(fitted(result2), 5))))


## compute scores of the one-step-ahead predictions
(sc <- scores(pred))

## the above uses the scores-method for "oneStepAhead" predictions,
## which is a simple wrapper around the default method:
# scores(x = pred$observed, mu = pred$pred, size = exp(pred$psi))

## scores with respect to the fitted values are similar
(scFitted <- scores(lymeTwtFit_basic, subset = nrow(observed)-(4:0)))




## test if the one-step-ahead predictions are calibrated
calibrationTest(pred)  # p = 0.8746

## the above uses the calibrationTest-method for "oneStepAhead" predictions,
## which is a simple wrapper around the default method:
calibrationTest(x = pred$observed, mu = pred$pred)

## we can also test calibration of the fitted values
## using the calibrationTest-method for "hhh4" fits
calibrationTest(lymeTwtFit_basic, subset = nrow(observed)-(4:0))


## plot a (non-randomized) PIT histogram for the predictions
pit(pred)
# 
# ## the above uses the pit-method for "oneStepAhead" predictions,
# ## which is a simple wrapper around the default method:
# pit(x = pred$observed, pdistr = "pnbinom", mu = pred$pred)
# 


colMeans(scores(pred, which = c("logs", "rps")))



```


```{r florida income moran i test}
# https://mgimond.github.io/simple_moransI_example/

s <- readRDS(url("https://github.com/mgimond/Data/raw/gh-pages/Exercises/nhme.rds"))

names(s)

s$Income


tm_shape(s) + tm_fill(col="Income", style="quantile", n=8, palette="Greens") +  tm_legend(outside=TRUE)

nb <- poly2nb(s, queen=TRUE)

lw <- nb2listw(nb, style="W", zero.policy=TRUE)

lw$weights[1]

I <- moran(s$Income, lw, length(nb), Szero(lw))[1]
I

moran.test(s$Income,lw, alternative="greater")

MC<- moran.mc(s$Income, lw, nsim=999, alternative="greater")
MC

plot(MC)

set.seed(111)
s$rand1 <- sample(s$Income, length(s$Income), replace = FALSE)
s$rand2 <- sample(s$Income, length(s$Income), replace = FALSE)
s$rand3 <- sample(s$Income, length(s$Income), replace = FALSE)

tm_shape(s) + tm_fill(col=c("Income", "rand1", "rand2", "rand3"),
                      style="quantile", n=8, palette="Greens", legend.show = FALSE) +
              tm_facets( nrow=1)


```



```{r MORON I Test Lyme Twtr Count}

mycounty = map("county","connecticut", fill=TRUE, plot=FALSE)
county.ID <- sapply(strsplit(mycounty$names, ","), function(x) x[2])
mypoly = map2SpatialPolygons(mycounty, IDs=county.ID)
nb = poly2nb(mypoly, queen=TRUE)
lw <- nb2listw(nb, style="W", zero.policy=TRUE)

I <- moran(observedTwt[108,], lw, length(nb), Szero(lw))[1]
I

moran.test(observedTwt[108,],lw, alternative="greater")



```

```{r MORON I Test Lyme Disease Count}

mycounty = map("county","connecticut", fill=TRUE, plot=FALSE)
county.ID <- sapply(strsplit(mycounty$names, ","), function(x) x[2])
mypoly = map2SpatialPolygons(mycounty, IDs=county.ID)
nb = poly2nb(mypoly, queen=TRUE)
lw <- nb2listw(nb, style="W", zero.policy=TRUE)

I <- moran(as.numeric(observed[108,]), lw, length(nb), Szero(lw))[1]
I

moran.test(as.numeric(observed[108,]),lw, alternative="greater")



```

```{r Bivariate Moran-I}
#https://stackoverflow.com/questions/45177590/map-of-bivariate-spatial-correlation-in-r-bivariate-lisa


#======================================================
# load data
data("oregon.tract")

# Variables to use in the correlation: white and black population in each census track
x <- oregon.tract$white
y <- oregon.tract$black

#======================================================
# Programming some functions

# Bivariate Moran's I
moran_I <- function(x, y = NULL, W){
        if(is.null(y)) y = x

        xp <- x #(x - mean(x, na.rm=T))/sd(x, na.rm=T)
        yp <- y #(y - mean(y, na.rm=T))/sd(y, na.rm=T)
        print(paste("xp",xp))
        print(paste("yp",yp))
        W[which(is.na(W))] <- 0
        n <- nrow(W)

        global <- (xp%*%W%*%yp)/(n - 1)
        local  <- (xp*W%*%yp)

        list(global = global, local  = as.numeric(local))
}


# Permutations for the Bivariate Moran's I
simula_moran <- function(x, y = NULL, W, nsims = 1000){

        if(is.null(y)) y = x

        n   = nrow(W)
        IDs = 1:n

        xp <- (x - mean(x, na.rm=T))/sd(x, na.rm=T)
        W[which(is.na(W))] <- 0

        global_sims = NULL
        local_sims  = matrix(NA, nrow = n, ncol=nsims)

        ID_sample = sample(IDs, size = n*nsims, replace = T)

        y_s = y[ID_sample]
        y_s = matrix(y_s, nrow = n, ncol = nsims)
        y_s <- (y_s - apply(y_s, 1, mean))/apply(y_s, 1, sd)

        global_sims  <- as.numeric( (xp%*%W%*%y_s)/(n - 1) )
        local_sims  <- (xp*W%*%y_s)

        list(global_sims = global_sims,
             local_sims  = local_sims)
}


#======================================================
# Adjacency Matrix (Queen)

nb <- poly2nb(oregon.tract)
lw <- nb2listw(nb, style = "B", zero.policy = T)
W  <- as(lw, "symmetricMatrix")
W  <- as.matrix(W/rowSums(W))
W[which(is.na(W))] <- 0

#======================================================
# Calculating the index and its simulated distribution
# for global and local values

m   <- moran_I(x, y, W)
m[[1]] # global value

m_i <- m[[2]]  # local values

local_sims <- simula_moran(x, y, W)$local_sims

# Identifying the significant values 
alpha <- .05  # for a 95% confidence interval
probs <- c(alpha/2, 1-alpha/2)
intervals <- t( apply(local_sims, 1, function(x) quantile(x, probs=probs)))
sig        <- ( m_i < intervals[,1] )  | ( m_i > intervals[,2] )

#======================================================
# Preparing for plotting

oregon.tract     <- st_as_sf(oregon.tract)
oregon.tract$sig <- sig


# Identifying the LISA patterns
xp <- (x-mean(x))/sd(x)
yp <- (y-mean(y))/sd(y)

patterns <- as.character( interaction(xp > 0, W%*%yp > 0) ) 
patterns <- patterns %>% 
        str_replace_all("TRUE","High") %>% 
        str_replace_all("FALSE","Low")
patterns[oregon.tract$sig==0] <- "Not significant"
oregon.tract$patterns <- patterns


# Plotting
ggplot() + geom_sf(data=oregon.tract, aes(fill=patterns), color="NA") +
        scale_fill_manual(values = c("red", "pink", "light blue", "dark blue", "grey95")) + 
        theme_minimal()



```

```{r connecticut Moran I spatial polygon}

# data("connecticut.tract")

i = 103 #103
t1 = c(as.numeric(observed[i,]))
x = t1/max(t1)

t2 = c(as.numeric(observedTwt[i,]))
y = t2/max(t2) #observedTwt[108,]


# mynb = poly2nb(mypoly)

mynb <- poly2nb(mypoly)
lw <- nb2listw(mynb, style = "B", zero.policy = T)
W  <- as(lw, "symmetricMatrix")
W  <- as.matrix(W/rowSums(W))
W[which(is.na(W))] <- 0

m   <- moran_I(x, y, W)

m_i <- m[[2]]
local_sims <- simula_moran(x, y, W)$local_sims

alpha <- .05  # for a 95% confidence interval
probs <- c(alpha/2, 1-alpha/2)
intervals <- t( apply(local_sims, 1, function(x) quantile(x, probs=probs)))
sig        <- ( m_i < intervals[,1] )  | ( m_i > intervals[,2] )
print(m[[1]]) # global value
sig

```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
